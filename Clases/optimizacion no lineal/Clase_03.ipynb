{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "ehCT2lXP3Sty",
        "pycharm": {
          "is_executing": false
        }
      },
      "source": [
        "### Introducción a la Investigación Operativa y la Optimización\n",
        "\n",
        "### • Polyak, Nesterov y ADAM\n",
        "\n",
        "**Nazareno Faillace Mullen - Departamento de Matemática, FCEN, UBA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JQs7GAsMKjMe"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from numpy.linalg import norm\n",
        "from time import time, perf_counter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQq60TbMUup2"
      },
      "source": [
        "# Método del gradiente con paso fijo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZI0tiKvUy8D"
      },
      "source": [
        "El Método de Gradiente con paso fijo consiste en fijar $\\gamma>0$ e iterar:\n",
        "$$x_{k+1} = x_k - \\gamma \\nabla f(x_k)$$\n",
        "\n",
        "**Teorema**: si $f:\\mathbb{R}^n\\rightarrow\\mathbb{R}$ es acotada inferiormente y $\\nabla f$ es Lipschitz, es decir, $\\exists L>0$ tal que:\n",
        "$$\\lVert \\nabla f(x) - \\nabla f(y)\\rVert \\leq L\\lVert x-y\\rVert \\quad \\forall\\;x,y\\in \\mathbb{R}^n$$\n",
        "entonces el Método de Gradiente con paso fijo converge para $\\gamma\\in(0, \\frac{2}{L})$.\n",
        "\n",
        "**Teorema**: si $f:\\mathbb{R}^n\\rightarrow\\mathbb{R}$ es convexa, acotada inferiormente y $\\nabla f$ es Lipschitz, tomando $\\gamma=\\frac{1}{L}$, el Método del Gradiente con paso fijo verifica que:\n",
        "$$f(x_k)-f(x^\\star) \\leq \\frac{L}{2k}\\lVert x^\\star - x_0\\rVert$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGJrIOjnJKBA"
      },
      "source": [
        "## Funciones cuadrátricas\n",
        "\n",
        "Consideremos la función cuadrática $f(x)=\\frac{1}{2}x^TQx + b^Tx + c$ con $Q$ definida positiva ($Q\\succ 0$). Hemos visto que:\n",
        "$$\\nabla f(x) = Qx+b$$\n",
        "\n",
        "En particular:\n",
        "$$\\nabla f(x) - \\nabla f(y) = (Qx+b) - (Qy+b) = Q(x-y) \\Rightarrow \\lVert \\nabla f(x) - \\nabla f(y)\\rVert \\leq \\lVert Q \\rVert \\lVert x-y\\rVert$$\n",
        "entonces ¡$\\nabla f$ es Lipschitz con constante $\\lVert Q \\rVert$!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZalV9eTrfL6d"
      },
      "source": [
        "### Ejercicio\n",
        "\n",
        "Consideremos la función $f(x)=\\frac{1}{2}x^T Q x$ con:\n",
        "$$Q=\\begin{pmatrix}1 & 0 & \\dots & \\dots & 0 \\\\\n",
        "0 & 2 & 0 & \\dots & 0 \\\\\n",
        "0 & 0 & 3 & \\dots & 0 \\\\\n",
        "\\vdots & \\ddots & \\ddots & \\ddots & \\vdots \\\\\n",
        "0 & \\dots & \\dots & 0 & N \\\\\n",
        "\\end{pmatrix}$$\n",
        "\n",
        "Como $Q$ es definida positiva, el mínimo es $x^\\star = (0,\\dots,0)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRpFGRFahRUO"
      },
      "source": [
        "1. Implementar la funcion `metodo_gradiente_cuad_fijo` que implemente el Método del Gradiente con paso fijo $\\frac{1}{L}$ para funciones cuadráticas. Esta función es análoga a `metodo_gradiente_cuad` que implementamos la clase pasada, pero la longitud del paso debe venir dada como argumento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lekoRqs6Uxi1"
      },
      "outputs": [],
      "source": [
        "def metodo_gradiente_cuad_fijo(A, b, x, paso, eps=1e-5, k_max=1000):\n",
        "  \"\"\"\n",
        "  Aplica el método del gradiente con paso fijo para funciones cuadraticas.\n",
        "  A : matriz de la funcion cuadratica (np.array)\n",
        "  b : vector de la funcion cuadratica (np.array)\n",
        "  x: punto inicial (numpy.array)\n",
        "  paso: longitud de paso fija (float | int)\n",
        "  eps: valor de tolerancia para la norma del gradiente (float)\n",
        "  k_max: limite de iteraciones (int)\n",
        "  \"\"\"\n",
        "  # COMPLETAR\n",
        "  k = 0\n",
        "  d = -A@x - b\n",
        "  while k <= k_max and np.linalg.norm(d) > eps:\n",
        "    x = x + paso*d\n",
        "    d = (-A)@x - b\n",
        "    k += 1\n",
        "  print(f'Cantidad de iteraciones: {k}')\n",
        "  return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UoW4wpiVifX2"
      },
      "source": [
        "2. Aplicar el método para $f(x)=\\frac{1}{2}x^T Q x$ con $N=10$ y un máximo de 10000 iteraciones y mostrar el resultado obtenido para cada uno de los siguientes casos:<br>\n",
        "a) con longitud de paso fija $\\frac{1}{\\lVert Q \\rVert}$<br><br>\n",
        "b) con longitud de paso fija $\\frac{2}{\\lVert Q \\rVert}$<br><br>\n",
        "c) con longitud de paso fija $\\frac{2.1}{\\lVert Q \\rVert}$<br><br>\n",
        "d) con longitud de paso fija $\\frac{0.8}{\\lVert Q \\rVert}$<br><br>\n",
        "¿Qué se observa?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "rOXZpzkgi_tS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cantidad de iteraciones: 110\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "np.float64(8.577329159116975e-11)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "N = 10\n",
        "b = np.zeros(N)\n",
        "x_0 = np.ones(N)\n",
        "Q = np.diag(np.arange(N)+1)\n",
        "\n",
        "x = metodo_gradiente_cuad_fijo(Q, b, x_0, 1/N, k_max=10000)\n",
        "x@Q@x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zhUGLE6jyX4"
      },
      "source": [
        "3. Para distintos valores de $N$, comparar la cantidad de iteraciones y tiempo de ejecución del Método del Gradiente con Paso Fijo $\\frac{1}{\\lVert Q \\rVert}$ con:\n",
        "- el Método de Gradiente para cuadráticas de la clase pasada (`metodo_gradiente_cuad`)\n",
        "- con el Método de Gradiente para cuadráticas con la mitad del paso óptimo en cada iteración (que llamaremos `metodo_gradiente_cuad_05`\n",
        "\n",
        "¿Qué observamos que sucede con `metodo_gradiente_cuad_fijo` a medida que aumenta $N$? ¿Por qué te parece que ocurre esto?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "UQyTwaBijSxb"
      },
      "outputs": [],
      "source": [
        "def metodo_gradiente_cuad(A, b, x, eps=1e-5, k_max=1000):\n",
        "  \"\"\"\n",
        "  Aplica el método del gradiente.\n",
        "  func: funcion a optimizar (function)\n",
        "  x: punto inicial (numpy.array)\n",
        "  eps: valor de tolerancia para la norma del gradiente (float)\n",
        "  k_max: limite de iteraciones (int)\n",
        "  \"\"\"\n",
        "  k = 0\n",
        "  d = -A@x - b\n",
        "  while k <= k_max and np.linalg.norm(d) > eps:\n",
        "    t = (d@d)/(d@A@d)\n",
        "    x = x + t*d\n",
        "    d = (-A)@x - b\n",
        "    k += 1\n",
        "  print(f'Cantidad de iteraciones: {k}')\n",
        "  return x\n",
        "\n",
        "def metodo_gradiente_cuad_05(A, b, x, eps=1e-5, k_max=1000):\n",
        "  \"\"\"\n",
        "  Aplica el método del gradiente con mitad del paso optimo.\n",
        "  func: funcion a optimizar (function)\n",
        "  x: punto inicial (numpy.array)\n",
        "  eps: valor de tolerancia para la norma del gradiente (float)\n",
        "  k_max: limite de iteraciones (int)\n",
        "  \"\"\"\n",
        "  k = 0\n",
        "  d = -A@x - b\n",
        "  while k <= k_max and np.linalg.norm(d) > eps:\n",
        "    t = (d@d)/(d@A@d)*0.5\n",
        "    x = x + t*d\n",
        "    d = (-A)@x - b\n",
        "    k += 1\n",
        "  print(f'Cantidad de iteraciones: {k}')\n",
        "  return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "RbQan7HrHb2k"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cantidad de iteraciones: 885\n",
            "Tiempo del Método del Gradiente: 0.10\n",
            "Cantidad de iteraciones: 214\n",
            "Tiempo del Método del Gradiente con mitad de t*: 0.02\n",
            "Cantidad de iteraciones: 1722\n",
            "Tiempo del Método de Gradiente con paso fijo: 0.05\n"
          ]
        }
      ],
      "source": [
        "N = 150\n",
        "b = np.zeros(N)\n",
        "x_0 = np.ones(N)\n",
        "Q = np.diag(np.arange(N)+1)\n",
        "\n",
        "grad_start = perf_counter()\n",
        "x = metodo_gradiente_cuad(Q, b, x_0, k_max=10000)\n",
        "print(f'Tiempo del Método del Gradiente: {perf_counter()-grad_start:.2f}')\n",
        "\n",
        "grad_05_start = perf_counter()\n",
        "x = metodo_gradiente_cuad_05(Q, b, x_0, k_max=10000)\n",
        "print(f'Tiempo del Método del Gradiente con mitad de t*: {perf_counter()-grad_05_start:.2f}')\n",
        "\n",
        "grad_fijo_start = perf_counter()\n",
        "x = metodo_gradiente_cuad_fijo(Q, b, x_0, 1/N, k_max=10000)\n",
        "print(f'Tiempo del Método de Gradiente con paso fijo: {perf_counter()-grad_fijo_start:.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zf5pEMSWSYU1"
      },
      "source": [
        "# Método de Polyak"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43FV0pOKSd3W"
      },
      "source": [
        "En cada iteración, Polyak propone agregar un término de inercia:\n",
        "$$x_{k+1} = x_k - \\alpha \\nabla f(x_k) + \\beta (x_k-x_{k-1})$$\n",
        "generalmente con $\\beta\\in [0,1]$.\n",
        "\n",
        "Para $f\\in C^2$ tal que existen $m,M>0$ tales que para todo $x$ los autovalores de $Hf(x)$ cumplen que $m\\leq \\lambda \\leq M$, Polyak demuestra que los valores óptimos para $\\alpha$ y $\\beta$ son:\n",
        "$$\\alpha = \\frac{4}{(\\sqrt{m}+\\sqrt{M})^2} \\quad \\beta=\\left(\\frac{\\sqrt{𝜅} - 1}{\\sqrt{𝜅} + 1}\\right)^2$$\n",
        "donde $𝜅=\\frac{M}{m}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCvd_CadrxIS"
      },
      "source": [
        "## Funciones cuadráticas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueZtiQFjr2n2"
      },
      "source": [
        "En el caso de las funciones cuadráticas, podemos tomar $m$ como el mínimo autovalor de $Q$ y $M$ como el máximo autovalor de $Q$.\n",
        "\n",
        "Entonces ¿qué representa $𝜅$?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "from numpy.linalg import norm\n",
        "\n",
        "def derivada_parcial(func,x,i):\n",
        "  \"\"\"\n",
        "  Aproxima la i-esima derivada parcial de la función en x, utilizando diferencias centradas.\n",
        "  func: función a la que se le desea calcular la i-esima derivada parcial (function)\n",
        "  x: punto en el cual se desea calcular la i-esima derivada parcial (array de numpy)\n",
        "  i: indice de la coordenada parcial (int)\n",
        "  \"\"\"\n",
        "  h = 0.1\n",
        "  e_i = np.zeros(x.shape[0])  # np.zeros(len(x))\n",
        "  e_i[i] = 1\n",
        "  z = (func(x + h*e_i) - func(x - h*e_i))/(2*h)\n",
        "  h = h/2\n",
        "  y = (func(x + h*e_i) - func(x - h*e_i))/(2*h)\n",
        "  error = norm(y-z)\n",
        "  eps = 1e-8\n",
        "  while error>eps and (y != np.nan) and (y != np.inf) and y!= 0:\n",
        "      error = norm(y-z)\n",
        "      z = y\n",
        "      h = h/2\n",
        "      y = (func(x + h*e_i) - func(x - h*e_i))/(2*h)\n",
        "  return z\n",
        "\n",
        "def gradiente(func,x):\n",
        "  \"\"\"\n",
        "  Aproxima el gradiente de la función en x.\n",
        "  func: función a la que se le desea calcular el gradiente (function)\n",
        "  x: punto en el cual se desea calcular el gradiente (array de numpy)\n",
        "  \"\"\"\n",
        "  grad = np.empty(x.shape[0]) # np.zeros(x.shape[0])\n",
        "  for i in range(x.shape[0]):\n",
        "    grad[i] = derivada_parcial(func, x, i)\n",
        "  return grad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9u6eY3FoVJ8"
      },
      "source": [
        "### Ejercicios"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNcL6zUpogjO"
      },
      "source": [
        "1. Implementar `metodo_polyak_cuad` que lleve a cabo el Método de Polyak para una función cuadrática. La función toma además como argumento los valores de $m$ y $M$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "r8_GDveinauA"
      },
      "outputs": [],
      "source": [
        "def metodo_polyak_cuad(A, b, x, m, M, eps=1e-5, k_max=1000):\n",
        "  \"\"\"\n",
        "  Aplica el método de Polyak para funciones cuadraticas.\n",
        "  A : matriz de la funcion cuadratica (np.array)\n",
        "  b : vector de la funcion cuadratica (np.array)\n",
        "  x: punto inicial (numpy.array)\n",
        "  m: valor que acota inferiormente los autovalores del hessiano (float)\n",
        "  M: valor que acota superiormente los autovalores del hessiano (float)\n",
        "  eps: valor de tolerancia para la norma del gradiente (float)\n",
        "  k_max: limite de iteraciones (int)\n",
        "  \"\"\"\n",
        "  xs = []\n",
        "  xs.append(x)\n",
        "  xs.append(x)\n",
        "  k = 1\n",
        "  d = -A@x - b\n",
        "  alpha = 4/((np.sqrt(m)+np.sqrt(M))**2)\n",
        "  ka = M/m\n",
        "  beta = ((np.sqrt(ka) - 1)/(np.sqrt(ka) + 1))**2\n",
        "  while k <= k_max and np.linalg.norm(d) > eps:\n",
        "    prevx = xs[k - 1]\n",
        "    xs.append(xs[k] - alpha*(Q@xs[k] + b) + beta*(xs[k] - prevx))\n",
        "    d = (-A)@xs[k+1] - b\n",
        "    k += 1\n",
        "  print(f'Cantidad de iteraciones: {k}')\n",
        "  return xs[k]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jhA_Wdyt9Z2"
      },
      "source": [
        "2. Aplicar el método a la función $f(x)=\\frac{1}{2}x^TQx$ para $Q$ definida en el ejercicio anterior, con $N=10$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "tDNdk8QxoTxR"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cantidad de iteraciones: 28\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "np.float64(7.83002367398256e-12)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "N = 10\n",
        "b = np.zeros(N)\n",
        "x_0 = np.ones(N)\n",
        "Q = np.diag(np.arange(N)+1)\n",
        "\n",
        "x = metodo_polyak_cuad(Q, b, x_0, 1, N)\n",
        "x@Q@x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nWr9jsavUyW"
      },
      "source": [
        "3. Para $N=1500$ y `k_max=10000`, ejecutar la siguiente celda para comparar el tiempo y la cantidad de iteraciones del Método de Polyak con `metodo_gradiente_cuad_05`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "QcChZByMJQSW"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cantidad de iteraciones: 890\n",
            "Tiempo del Método del Gradiente con mitad de t*: 25.81\n",
            "Cantidad de iteraciones: 499\n",
            "Tiempo del Método de Polyak: 14.17\n"
          ]
        }
      ],
      "source": [
        "N = 1500\n",
        "b = np.zeros(N)\n",
        "x_0 = np.ones(N)\n",
        "Q = np.diag(np.arange(N)+1)\n",
        "\n",
        "grad_05_start = perf_counter()\n",
        "x = metodo_gradiente_cuad_05(Q, b, x_0, k_max=10000)\n",
        "print(f'Tiempo del Método del Gradiente con mitad de t*: {perf_counter()-grad_05_start:.2f}')\n",
        "\n",
        "polyak_start = perf_counter()\n",
        "x = metodo_polyak_cuad(Q, b, x_0, 1, N, k_max=10000)\n",
        "print(f'Tiempo del Método de Polyak: {perf_counter()-polyak_start:.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWtJywG82DOG"
      },
      "source": [
        "# Método de Nesterov (_Nestorov Accelerated Gradient_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWF3Ffa32KLn"
      },
      "source": [
        "Nesterov propone modificar el punto donde se calcula el gradiente:\n",
        "$$x_{k+1} = x_k - \\alpha_k \\nabla f(x_k+ \\beta_k(x_k-x_{k-1})) + \\beta (x_k-x_{k-1})$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzX1KcPD452b"
      },
      "source": [
        "Para $f\\in C^2$ tal que existen $m,M>0$ tales que para todo $x$ los autovalores de $Hf(x)$ cumplen que $m\\leq \\lambda \\leq M$, Nesterov prueba que es óptimo  fijar $\\alpha_k$ y $\\beta_k$ en:\n",
        "$$\\alpha = \\frac{1}{M} \\quad \\beta=\\frac{\\sqrt{M} - \\sqrt{m}}{\\sqrt{M} + \\sqrt{m}}$$\n",
        "\n",
        "En este caso, se puede probar que:\n",
        "$$f(x_k)-f(x^\\star) \\leq \\frac{2L}{(k+1)^2}\\lVert x^\\star - x_0\\rVert^2$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogRdgwA65rcP"
      },
      "source": [
        "## Ejercicios"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xwpSJIB5tV2"
      },
      "source": [
        "1. Implementar la funcion `metodo_nesterov_cuad` que aplique el Método de Nesterov a funciones cuadráticas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "1PD30-D-2C6y"
      },
      "outputs": [],
      "source": [
        "def metodo_nesterov_cuad(A, b, x, m, M, eps=1e-5, k_max=1000):\n",
        "  \"\"\"\n",
        "  Aplica el método de Nesterov para funciones cuadraticas.\n",
        "  A : matriz de la funcion cuadratica (np.array)\n",
        "  b : vector de la funcion cuadratica (np.array)\n",
        "  x: punto inicial (numpy.array)\n",
        "  m: valor que acota inferiormente los autovalores del hessiano (float)\n",
        "  M: valor que acota superiormente los autovalores del hessiano (float)\n",
        "  eps: valor de tolerancia para la norma del gradiente (float)\n",
        "  k_max: limite de iteraciones (int)\n",
        "  \"\"\"\n",
        "  \n",
        "  xs = []\n",
        "  xs.append(x)\n",
        "  xs.append(x)\n",
        "  k = 1\n",
        "  d = -A@x - b\n",
        "  alpha = 1/M\n",
        "  beta = ((np.sqrt(M) - np.sqrt(m))/(np.sqrt(M) + np.sqrt(m)))\n",
        "  while k <= k_max and np.linalg.norm(d) > eps:\n",
        "    prevx = xs[k - 1]\n",
        "    xs.append(xs[k] - alpha*(Q@(xs[k]+beta*(xs[k] - prevx))) + beta*(xs[k] - prevx))\n",
        "    d = (-A)@xs[k+1] - b\n",
        "    k += 1\n",
        "  print(f'Cantidad de iteraciones Nesterov: {k}')\n",
        "  return xs[k]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLaqG2qlIoUN"
      },
      "source": [
        "2. Aplicar el método a la función $f(x)=\\frac{1}{2}x^TQx$ para $Q$ definida en el ejercicio anterior, con $N=10$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "s5GTrryKItWS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cantidad de iteraciones Nesterov: 38\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "np.float64(9.798392023683198e-11)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "N = 10\n",
        "b = np.zeros(N)\n",
        "x_0 = np.ones(N)\n",
        "Q = np.diag(np.arange(N)+1)\n",
        "\n",
        "x = metodo_nesterov_cuad(Q, b, x_0, 1, N, k_max=100000)\n",
        "x@Q@x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQVIBBbbI78O"
      },
      "source": [
        "3. Para $N=1500$, comparar el tiempo y la cantidad de iteraciones con `metodo_gradiente_cuad` y `metodo_polyak_cuad`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "L2HRYVsAKoS6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cantidad de iteraciones: 890\n",
            "Tiempo del Método del Gradiente con mitad de t*: 25.41\n",
            "Cantidad de iteraciones: 499\n",
            "Tiempo del Método de Polyak: 14.18\n",
            "Cantidad de iteraciones Nesterov: 549\n",
            "Tiempo del Método de Nesterov: 15.70\n"
          ]
        }
      ],
      "source": [
        "N = 1500\n",
        "b = np.zeros(N)\n",
        "x_0 = np.ones(N)\n",
        "Q = np.diag(np.arange(N)+1)\n",
        "\n",
        "grad_05_start = perf_counter()\n",
        "x = metodo_gradiente_cuad_05(Q, b, x_0, k_max=10000)\n",
        "print(f'Tiempo del Método del Gradiente con mitad de t*: {perf_counter()-grad_05_start:.2f}')\n",
        "\n",
        "polyak_start = perf_counter()\n",
        "x = metodo_polyak_cuad(Q, b, x_0, 1, N, k_max=10000)\n",
        "print(f'Tiempo del Método de Polyak: {perf_counter()-polyak_start:.2f}')\n",
        "\n",
        "nesterov_start = perf_counter()\n",
        "x = metodo_nesterov_cuad(Q, b, x_0, 1, N, k_max=10000)\n",
        "print(f'Tiempo del Método de Nesterov: {perf_counter()-nesterov_start:.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeEneBWdDPwr"
      },
      "source": [
        "# ADAM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQdTjnbNGjFv"
      },
      "source": [
        "ADAM es uno de los métodos más utilizados actualmente, especialmente para Redes Neuronales. Por un lado, consideramos el **momento** como una media móvil exponencial de los gradientes de iteraciones anteriores:\n",
        "$$m_{k+1} = \\beta_1 m_{k}+(1-\\beta_1)\\nabla f(x_{k}) \\quad \\beta_1\\in[0,1)$$\n",
        "\n",
        "Por otro lado, consideramos la media móvil de las magnitudes de los gradientes de iteraciones anteriores:\n",
        "$$v_{k+1} = \\beta_2 v_{k} + (1-\\beta_2)\\underbrace{\\nabla f(x_k)\\odot ∇f(x_k)}_{\\substack{\\text{multiplicación} \\\\ \\text{coordenada a coordenada}}}$$\n",
        "\n",
        "La actualización del paso en cada iteración se da por:\n",
        "$$x_{k+1} = x_k - \\alpha \\frac{m_k}{\\sqrt{v_k}+\\varepsilon}$$\n",
        "donde $\\varepsilon$ es incluido para estabilidad numérica y evitar dividir por $0$ (podemos tomar $\\varepsilon=10^{-8}$).\n",
        "\n",
        "Como $m_0=v_0=0$, para evitar que los $m_k$ y los $v_k$ estén muy sesgados hacia $0$, en cada iteración se realiza una corrección:\n",
        "$$\\hat{m}_k=\\frac{m_k}{(1-\\beta_1^k)} \\quad \\hat{v_k}=\\frac{v_t}{(1-\\beta_2^k)}$$\n",
        "y consideraremos:\n",
        "$$x_{k+1} = x_k - \\alpha \\frac{\\hat{m}_k}{\\sqrt{\\hat{v}_k}+\\varepsilon}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsQYBLlZeWXM"
      },
      "source": [
        "Valores usuales de los parámetros: $\\alpha < 1,\\; \\beta_1=0.9,\\; \\beta_2=0.99$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RX47pO5feS5U"
      },
      "source": [
        "**Pseudocódigo de ADAM**\n",
        "\n",
        "adam($f$,$x$, $\\alpha$, $\\beta_1$, $\\beta_2$, $max\\_iter$):<br>\n",
        "&nbsp; &nbsp; $k$ $\\leftarrow$ $0$ <br>\n",
        "&nbsp; &nbsp; $m$ $\\leftarrow$ $0$ <br>\n",
        "&nbsp; &nbsp; $v$ $\\leftarrow$ $0$ <br>\n",
        "&nbsp; &nbsp; $d$ $\\leftarrow$ $\\nabla f(x)$ &nbsp; &nbsp; `# Dirección del primer paso` <br>\n",
        "&nbsp; &nbsp; MIENTRAS $k\\leq max\\_iter$ and $\\lVert d\\rVert$ $> 10^{-8}$: <br>\n",
        "&nbsp; &nbsp; &nbsp; &nbsp; $k\\leftarrow k + 1$ <br>\n",
        "&nbsp; &nbsp; &nbsp; &nbsp; $m\\leftarrow \\beta_1m + (1-\\beta_1)d$ <br>\n",
        "&nbsp; &nbsp; &nbsp; &nbsp; $v\\leftarrow \\beta_2v + (1-\\beta_2)(d\\odot d)$ <br>\n",
        "&nbsp; &nbsp; &nbsp; &nbsp; $\\hat{m}\\leftarrow \\frac{m}{(1-\\beta_1^k)}$ <br>\n",
        "&nbsp; &nbsp; &nbsp; &nbsp; $\\hat{v}\\leftarrow \\frac{v}{(1-\\beta_2^k)}$ <br>\n",
        "&nbsp; &nbsp; &nbsp; &nbsp; $x$ $\\leftarrow$ $x - \\alpha \\frac{\\hat{m}}{\\sqrt{\\hat{v}}+10^{-8}}$ &nbsp; &nbsp; <br>\n",
        "&nbsp; &nbsp; &nbsp; &nbsp; $d$ $\\leftarrow$ $\\nabla f(x)$  <br>\n",
        "&nbsp; &nbsp; DEVOLVER $x$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NTV3Z4FgpjW"
      },
      "source": [
        "## Ejercicios"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyKXv6qAgrCP"
      },
      "source": [
        "1. Implementar `adam_cuad` que aplica ADAM a funciones cuadráticas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "jAlKEFe-DR9m"
      },
      "outputs": [],
      "source": [
        "def adam_cuad(A, b, x, alpha, beta_1=0.9, beta_2=0.99, eps=1e-5, k_max=1000):\n",
        "  \"\"\"\n",
        "  Aplica ADAM para funciones cuadraticas.\n",
        "  A : matriz de la funcion cuadratica (np.array)\n",
        "  b : vector de la funcion cuadratica (np.array)\n",
        "  x: punto inicial (numpy.array)\n",
        "  alpha: longitud del paso (float)\n",
        "  beta_1: parametro del momento (float)\n",
        "  beta_2: parametro del modificador de la longitud de paso (float)\n",
        "  eps: valor de tolerancia para la norma del gradiente (float)\n",
        "  k_max: limite de iteraciones (int)\n",
        "  \"\"\"\n",
        "  # COMPLETAR\n",
        "  print(f'Cantidad de iteraciones: {k}')\n",
        "  return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeliDZHvhPqK"
      },
      "source": [
        "2. Para corroborar la correcta implementación, aplicar ADAM a la función $f(x)=\\frac{1}{2}x^TQx$ para $Q$ definida en el ejercicio anterior, con $N=10$ y $\\alpha=0.01$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8WkqW8mFBSh",
        "outputId": "fd71bdd2-f9fc-4e4d-91a9-aa700770f498"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid syntax (42446363.py, line 6)",
          "output_type": "error",
          "traceback": [
            "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mx = adam_cuad(???)\u001b[39m\n                  ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "N = 10\n",
        "b = np.zeros(N)\n",
        "x_0 = np.ones(N)\n",
        "Q = np.diag(np.arange(N)+1)\n",
        "\n",
        "x = adam_cuad(???)\n",
        "x@Q@x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ARtUlT4hVOD"
      },
      "source": [
        "3. Para $N=1500$ y `k_max=10000`, comparar ADAM ($\\alpha=0.01$) con Polyak y Nesterov. Experimentar con distintos puntos iniciales y valores de $\\alpha$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLWQekhmha6C",
        "outputId": "83675b30-0883-4913-baf9-52b22353fde3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cantidad de iteraciones: 340\n",
            "Tiempo del Método del Gradiente con mitad de t*: 3.07\n",
            "Cantidad de iteraciones: 497\n",
            "Tiempo del Método de Polyak: 4.83\n",
            "Cantidad de iteraciones: 546\n",
            "Tiempo del Método de Nesterov: 6.85\n"
          ]
        }
      ],
      "source": [
        "N = 1500\n",
        "b = np.zeros(N)\n",
        "x_0 = np.ones(N)\n",
        "Q = np.diag(np.arange(N)+1)\n",
        "\n",
        "adam_start = perf_counter()\n",
        "x = adam_cuad(Q, b, x_0, alpha=0.01, k_max=10000)\n",
        "print(f'Tiempo de ADAM: {perf_counter()-adam_start:.2f}')\n",
        "\n",
        "polyak_start = perf_counter()\n",
        "x = metodo_polyak_cuad(Q, b, x_0, 1, N, k_max=10000)\n",
        "print(f'Tiempo del Método de Polyak: {perf_counter()-polyak_start:.2f}')\n",
        "\n",
        "nesterov_start = perf_counter()\n",
        "x = metodo_nesterov_cuad(Q, b, x_0, 1, N, k_max=10000)\n",
        "print(f'Tiempo del Método de Nesterov: {perf_counter()-nesterov_start:.2f}')"
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
